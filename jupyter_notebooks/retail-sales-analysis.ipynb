{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Retail Sales Analysis Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Write your notebook objective here, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* Write down which data or information you need to run the notebook \n",
    "\n",
    "* Here i will explain df_raw\n",
    "\n",
    "## Tranformations\n",
    "\n",
    "* Here I will explain df_transform\n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Here I will explain denormalised_df (clean) and promo_denormalised_df (clean)\n",
    "\n",
    "* Write here which files, code or artefacts you generate by the end of the notebook \n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* If you have any additional comments that don't fit in the previous bullets, please state them here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Data Extract & Dictionary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd                        # Data manipulation and analysis\n",
    "import numpy as np                         # Numerical computing and operations\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt            # Basic plotting and charting\n",
    "import seaborn as sns                      # Statistical data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julianelliott/Documents/GitHub/retail-sales-analysis/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded to: /Users/julianelliott/.cache/kagglehub/datasets/manjeetsingh/retaildataset/versions/2\n",
      "Files copied to ../data\n"
     ]
    }
   ],
   "source": [
    "# Directory Management\n",
    "import os                                  # Import os for data directory management\n",
    "import shutil                              # Import shutil for file operations\n",
    "\n",
    "# Data Acquisition Library\n",
    "import kagglehub                           # Import Kaggle Hub to Download retail datasets\n",
    "\n",
    "# Download dataset \n",
    "path = kagglehub.dataset_download(\"manjeetsingh/retaildataset\")\n",
    "print(f'Files downloaded to: {path}')\n",
    "\n",
    "# Copy CSV files to data directory\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        shutil.copy2(os.path.join(path, file), f\"../data/{file.lower().replace(' ', '-')}\")\n",
    "\n",
    "# backlog feat: remove files from the kaggle cashe folder on copy see â‰ˆ\n",
    "# https://github.com/users/Julian-Elliott/projects/3/views/1?pane=issue&itemId=115149029&issue=Julian-Elliott%7Cretail-sales-analysis%7C13\n",
    "print(\"Files copied to ../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the retail datasets into dataframes\n",
    "sales_df_raw = pd.read_csv(\"../data/sales-data-set.csv\")\n",
    "stores_df_raw = pd.read_csv(\"../data/stores-data-set.csv\") \n",
    "features_df_raw = pd.read_csv(\"../data/features-data-set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting Dataset Data and building a data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw data Dictionary (before transformation)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Row Count</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing %</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Sample Values</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>421570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>1, 1, 1</td>\n",
       "      <td>The store number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales</td>\n",
       "      <td>Dept</td>\n",
       "      <td>int64</td>\n",
       "      <td>421570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>81</td>\n",
       "      <td>1, 1, 1</td>\n",
       "      <td>The department number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales</td>\n",
       "      <td>Date</td>\n",
       "      <td>object</td>\n",
       "      <td>421570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>143</td>\n",
       "      <td>05/02/2010, 12/02/2010, 19/02/2010</td>\n",
       "      <td>The week start date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sales</td>\n",
       "      <td>Weekly_Sales</td>\n",
       "      <td>float64</td>\n",
       "      <td>421570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>359464</td>\n",
       "      <td>24924.5, 46039.49, 41595.55</td>\n",
       "      <td>Sales for the given department in the given store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sales</td>\n",
       "      <td>IsHoliday</td>\n",
       "      <td>bool</td>\n",
       "      <td>421570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>False, True, False</td>\n",
       "      <td>Whether the week is a special holiday week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stores</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>1, 2, 3</td>\n",
       "      <td>The store number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stores</td>\n",
       "      <td>Type</td>\n",
       "      <td>object</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>A, A, B</td>\n",
       "      <td>Store type classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stores</td>\n",
       "      <td>Size</td>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40</td>\n",
       "      <td>151315, 202307, 37392</td>\n",
       "      <td>Store size in square feet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Features</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>8190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45</td>\n",
       "      <td>1, 1, 1</td>\n",
       "      <td>The store number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Features</td>\n",
       "      <td>Date</td>\n",
       "      <td>object</td>\n",
       "      <td>8190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182</td>\n",
       "      <td>05/02/2010, 12/02/2010, 19/02/2010</td>\n",
       "      <td>The week start date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Features</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4178</td>\n",
       "      <td>42.31, 38.51, 39.93</td>\n",
       "      <td>Average temperature in the region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Features</td>\n",
       "      <td>Fuel_Price</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1011</td>\n",
       "      <td>2.572, 2.548, 2.514</td>\n",
       "      <td>Cost of fuel in the region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Features</td>\n",
       "      <td>MarkDown1</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>4158</td>\n",
       "      <td>50.77</td>\n",
       "      <td>4023</td>\n",
       "      <td>10382.9, 6074.12, 410.31</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Features</td>\n",
       "      <td>MarkDown2</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>5269</td>\n",
       "      <td>64.33</td>\n",
       "      <td>2715</td>\n",
       "      <td>6115.67, 254.39, 98.0</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Features</td>\n",
       "      <td>MarkDown3</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>4577</td>\n",
       "      <td>55.89</td>\n",
       "      <td>2885</td>\n",
       "      <td>215.07, 51.98, 55805.51</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Features</td>\n",
       "      <td>MarkDown4</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>4726</td>\n",
       "      <td>57.70</td>\n",
       "      <td>3405</td>\n",
       "      <td>2406.62, 427.39, 8.0</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Features</td>\n",
       "      <td>MarkDown5</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>4140</td>\n",
       "      <td>50.55</td>\n",
       "      <td>4045</td>\n",
       "      <td>6551.42, 5988.57, 554.92</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Features</td>\n",
       "      <td>CPI</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>585</td>\n",
       "      <td>7.14</td>\n",
       "      <td>2505</td>\n",
       "      <td>211.0963582, 211.2421698, 211.2891429</td>\n",
       "      <td>The consumer price index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Features</td>\n",
       "      <td>Unemployment</td>\n",
       "      <td>float64</td>\n",
       "      <td>8190</td>\n",
       "      <td>585</td>\n",
       "      <td>7.14</td>\n",
       "      <td>404</td>\n",
       "      <td>8.106, 8.106, 8.106</td>\n",
       "      <td>The unemployment rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Features</td>\n",
       "      <td>IsHoliday</td>\n",
       "      <td>bool</td>\n",
       "      <td>8190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>False, True, False</td>\n",
       "      <td>Whether the week is a special holiday week</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dataset        Column Data Type  Row Count  Missing Values  Missing %  \\\n",
       "0      Sales         Store     int64     421570               0       0.00   \n",
       "1      Sales          Dept     int64     421570               0       0.00   \n",
       "2      Sales          Date    object     421570               0       0.00   \n",
       "3      Sales  Weekly_Sales   float64     421570               0       0.00   \n",
       "4      Sales     IsHoliday      bool     421570               0       0.00   \n",
       "5     Stores         Store     int64         45               0       0.00   \n",
       "6     Stores          Type    object         45               0       0.00   \n",
       "7     Stores          Size     int64         45               0       0.00   \n",
       "8   Features         Store     int64       8190               0       0.00   \n",
       "9   Features          Date    object       8190               0       0.00   \n",
       "10  Features   Temperature   float64       8190               0       0.00   \n",
       "11  Features    Fuel_Price   float64       8190               0       0.00   \n",
       "12  Features     MarkDown1   float64       8190            4158      50.77   \n",
       "13  Features     MarkDown2   float64       8190            5269      64.33   \n",
       "14  Features     MarkDown3   float64       8190            4577      55.89   \n",
       "15  Features     MarkDown4   float64       8190            4726      57.70   \n",
       "16  Features     MarkDown5   float64       8190            4140      50.55   \n",
       "17  Features           CPI   float64       8190             585       7.14   \n",
       "18  Features  Unemployment   float64       8190             585       7.14   \n",
       "19  Features     IsHoliday      bool       8190               0       0.00   \n",
       "\n",
       "    Unique Values                          Sample Values  \\\n",
       "0              45                                1, 1, 1   \n",
       "1              81                                1, 1, 1   \n",
       "2             143     05/02/2010, 12/02/2010, 19/02/2010   \n",
       "3          359464            24924.5, 46039.49, 41595.55   \n",
       "4               2                     False, True, False   \n",
       "5              45                                1, 2, 3   \n",
       "6               3                                A, A, B   \n",
       "7              40                  151315, 202307, 37392   \n",
       "8              45                                1, 1, 1   \n",
       "9             182     05/02/2010, 12/02/2010, 19/02/2010   \n",
       "10           4178                    42.31, 38.51, 39.93   \n",
       "11           1011                    2.572, 2.548, 2.514   \n",
       "12           4023               10382.9, 6074.12, 410.31   \n",
       "13           2715                  6115.67, 254.39, 98.0   \n",
       "14           2885                215.07, 51.98, 55805.51   \n",
       "15           3405                   2406.62, 427.39, 8.0   \n",
       "16           4045               6551.42, 5988.57, 554.92   \n",
       "17           2505  211.0963582, 211.2421698, 211.2891429   \n",
       "18            404                    8.106, 8.106, 8.106   \n",
       "19              2                     False, True, False   \n",
       "\n",
       "                                          Description  \n",
       "0                                    The store number  \n",
       "1                               The department number  \n",
       "2                                 The week start date  \n",
       "3   Sales for the given department in the given store  \n",
       "4          Whether the week is a special holiday week  \n",
       "5                                    The store number  \n",
       "6                           Store type classification  \n",
       "7                           Store size in square feet  \n",
       "8                                    The store number  \n",
       "9                                 The week start date  \n",
       "10                  Average temperature in the region  \n",
       "11                         Cost of fuel in the region  \n",
       "12  Anonymized promotional markdown data (after No...  \n",
       "13  Anonymized promotional markdown data (after No...  \n",
       "14  Anonymized promotional markdown data (after No...  \n",
       "15  Anonymized promotional markdown data (after No...  \n",
       "16  Anonymized promotional markdown data (after No...  \n",
       "17                           The consumer price index  \n",
       "18                              The unemployment rate  \n",
       "19         Whether the week is a special holiday week  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Custom Function to create a comprehensive data dictionary for multiple datasets as I experienced issues with ydata-profiling\n",
    "def create_data_dictionary(datasets_dict):\n",
    "    # Quick ref for detailed descriptions for each known column (from Kaggle data card https://www.kaggle.com/datasets/manjeetsingh/retaildataset/data)\n",
    "    descriptions = {\n",
    "        'Store': 'The store number',\n",
    "        'Date': 'The week start date',\n",
    "        'Temperature': 'Average temperature in the region',\n",
    "        'Fuel_Price': 'Cost of fuel in the region',\n",
    "        'MarkDown1': 'Anonymized promotional markdown data (after Nov 2011)',\n",
    "        'MarkDown2': 'Anonymized promotional markdown data (after Nov 2011)',\n",
    "        'MarkDown3': 'Anonymized promotional markdown data (after Nov 2011)',\n",
    "        'MarkDown4': 'Anonymized promotional markdown data (after Nov 2011)',\n",
    "        'MarkDown5': 'Anonymized promotional markdown data (after Nov 2011)',\n",
    "        'CPI': 'The consumer price index',\n",
    "        'Unemployment': 'The unemployment rate',\n",
    "        'IsHoliday': 'Whether the week is a special holiday week',\n",
    "        'Dept': 'The department number',\n",
    "        'Weekly_Sales': 'Sales for the given department in the given store',\n",
    "        'Type': 'Store type classification',\n",
    "        'Size': 'Store size in square feet'\n",
    "    }\n",
    "    \n",
    "    dictionary_data = []\n",
    "    for dataset_name, df in datasets_dict.items():\n",
    "        for column in df.columns:\n",
    "            # Get 3 sample values (non-null)\n",
    "            sample_values = df[column].dropna().head(3).tolist()\n",
    "            sample_str = ', '.join([str(x) for x in sample_values])\n",
    "            \n",
    "            dictionary_data.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Column': column,\n",
    "                'Data Type': str(df[column].dtype),\n",
    "                'Row Count': len(df),\n",
    "                'Missing Values': df[column].isnull().sum(),\n",
    "                'Missing %': round((df[column].isnull().sum() / len(df)) * 100, 2),\n",
    "                'Unique Values': df[column].nunique(),\n",
    "                'Sample Values': sample_str,\n",
    "                'Description': descriptions.get(column, 'Description needed')\n",
    "            })\n",
    "    return pd.DataFrame(dictionary_data)\n",
    "\n",
    "# Create datasets dictionary\n",
    "datasets = {\n",
    "    'Sales': sales_df_raw,\n",
    "    'Stores': stores_df_raw,\n",
    "    'Features': features_df_raw\n",
    "}\n",
    "\n",
    "# Generate data dictionary that can be called upon later\n",
    "data_dictionary = create_data_dictionary(datasets)\n",
    "\n",
    "print('\\nRaw data Dictionary (before transformation)')\n",
    "# Display data dictionary\n",
    "data_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential Issues shown in the Data Dictionary\n",
    "\n",
    "Markdown columns `1` through `5`, `CPI` and `Unemployment` in the `Features` dataset presents notable data quality challenges:\n",
    "\n",
    "- **Missing Data:**  \n",
    "  Each MarkDown column contains a significant percentage of missing values (ranging from 50% to over 64%). Part of this is expected, as promotional markdown data is only available after November 2011, and earlier records do not include these values.  \n",
    "  To a lesser extent, the `CPI` (Consumer Price Index) and `Unemployment` columns are also missing about 7% of their values. While this is less dramatic, it may still impact analyses involving economic features of our dataset.\n",
    "  \n",
    "- **Time-Dependent Availability:**  \n",
    "  The fact that MarkDown data is only present for dates after November 2011 (as explained in the kaggle [data card](https://www.kaggle.com/datasets/manjeetsingh/retaildataset/data)) means that analyses involving these columns must account for their partial availability. Any models or insights involving markdowns will be biased toward the later part of the dataset and may not generalise to earlier periods.\n",
    "\n",
    "- **Other Features:**  \n",
    "  Other columns such as `Store`, `Date`, `Temperature`, `IsHoliday` and `Weekly_Sales` have no missing values and can be used with greater confidence in a general analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary dataframes to avoid modifying the original data before transform stage\n",
    "sales_df_transform = sales_df_raw.copy()\n",
    "features_df_transform = features_df_raw.copy()\n",
    "stores_df_transform = stores_df_raw.copy()\n",
    "\n",
    "# Convert temp date columns with correct format (DD/MM/YYYY)\n",
    "sales_df_transform['Date'] = pd.to_datetime(sales_df_transform['Date'], format='%d/%m/%Y')\n",
    "features_df_transform['Date'] = pd.to_datetime(features_df_transform['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Find the first date where any MarkDown data is available\n",
    "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "first_markdown_date = features_df_transform[features_df_transform[markdown_cols].notna().any(axis=1)]['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of date ranges across datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Records</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>End_Date</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sales-data-set.csv</td>\n",
       "      <td>421570</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>Weekly sales data spanning 45 stores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>features-data-set.csv</td>\n",
       "      <td>8190</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>Economic and promotional features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>markdown-features</td>\n",
       "      <td>4050</td>\n",
       "      <td>2011-11-11</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>Promotional markdown data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dataset  Records  Start_Date    End_Date  \\\n",
       "0     sales-data-set.csv   421570  2010-02-05  2012-10-26   \n",
       "1  features-data-set.csv     8190  2010-02-05  2013-07-26   \n",
       "2      markdown-features     4050  2011-11-11  2013-07-26   \n",
       "\n",
       "                            Description  \n",
       "0  Weekly sales data spanning 45 stores  \n",
       "1     Economic and promotional features  \n",
       "2             Promotional markdown data  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a summary dataframe of the datasets with date ranges and markdown info\n",
    "dataset_summary = pd.DataFrame({\n",
    "    'Dataset': ['sales-data-set.csv', 'features-data-set.csv', 'markdown-features'],\n",
    "    'Records': [\n",
    "        sales_df_transform.shape[0], \n",
    "        features_df_transform.shape[0], \n",
    "        features_df_transform[features_df_transform[markdown_cols].notna().any(axis=1)].shape[0]\n",
    "    ],\n",
    "    'Start_Date': [\n",
    "        sales_df_transform[\"Date\"].min().strftime(\"%Y-%m-%d\"),  # Sales data start date using transform df\n",
    "        features_df_transform[\"Date\"].min().strftime(\"%Y-%m-%d\"),  # Features data start date using transform df\n",
    "        first_markdown_date.strftime(\"%Y-%m-%d\")  # First date with markdown data\n",
    "    ],\n",
    "    'End_Date': [\n",
    "        sales_df_transform[\"Date\"].max().strftime(\"%Y-%m-%d\"),  # Sales data end date using transform df\n",
    "        features_df_transform[\"Date\"].max().strftime(\"%Y-%m-%d\"),  # Features data end date using transform df\n",
    "        features_df_transform[\"Date\"].max().strftime(\"%Y-%m-%d\")  # Markdown data shares same end date as features\n",
    "    ],\n",
    "    'Description': [\n",
    "        f'Weekly sales data spanning {stores_df_raw.shape[0]} stores',  # Sales dataset description\n",
    "        'Economic and promotional features',  # Features dataset description\n",
    "        f'Promotional markdown data'  # Markdown subset description\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('\\nComparison of date ranges across datasets:')\n",
    "\n",
    "dataset_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARED COLUMNS (JOIN KEYS):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales_Transform</td>\n",
       "      <td>Date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Features_Transform</td>\n",
       "      <td>Date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sales_Transform</td>\n",
       "      <td>IsHoliday</td>\n",
       "      <td>bool</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Features_Transform</td>\n",
       "      <td>IsHoliday</td>\n",
       "      <td>bool</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales_Transform</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stores_Transform</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Features_Transform</td>\n",
       "      <td>Store</td>\n",
       "      <td>int64</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Dataset     Column       Data Type  Unique Values\n",
       "2      Sales_Transform       Date  datetime64[ns]            143\n",
       "9   Features_Transform       Date  datetime64[ns]            182\n",
       "4      Sales_Transform  IsHoliday            bool              2\n",
       "19  Features_Transform  IsHoliday            bool              2\n",
       "0      Sales_Transform      Store           int64             45\n",
       "5     Stores_Transform      Store           int64             45\n",
       "8   Features_Transform      Store           int64             45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use data dictionary to identify matching columns between transform datasets\n",
    "transform_datasets = {\n",
    "    'Sales_Transform': sales_df_transform,\n",
    "    'Stores_Transform': stores_df_transform, \n",
    "    'Features_Transform': features_df_transform\n",
    "}\n",
    "\n",
    "# Generate data dictionary for transform datasets\n",
    "transform_dictionary = create_data_dictionary(transform_datasets)\n",
    "\n",
    "# Find columns that appear in multiple datasets\n",
    "column_counts = transform_dictionary['Column'].value_counts()\n",
    "shared_columns = column_counts[column_counts > 1]\n",
    "\n",
    "print(\"SHARED COLUMNS (JOIN KEYS):\")\n",
    "# Only show rows for columns that appear in multiple datasets\n",
    "shared_dict = transform_dictionary[transform_dictionary['Column'].isin(shared_columns.index)]\n",
    "shared_dict[['Dataset', 'Column', 'Data Type', 'Unique Values']].sort_values('Column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Relationships Between Tables\n",
    "\n",
    "The retail dataset appears to follow a **Star Schema** pattern with clear relationships between the three main tables:\n",
    "\n",
    "#### **Join Keys Identified**\n",
    "- **Sales â†” Stores**: `Store` (Many-to-One relationship)\n",
    "- **Sales â†” Features**: `Store` + `Date` composite key (One-to-One relationship)\n",
    "\n",
    "#### **Table Roles**\n",
    "- **SALES**: Central fact table containing transactional data\n",
    "  - Granularity: Store + Department + Week level\n",
    "  - Contains measurable metrics (Weekly_Sales)\n",
    "  \n",
    "- **STORES**: Dimension table with store characteristics\n",
    "  - Granularity: Store level (static attributes)\n",
    "  - Contains: Store type, size, and other store properties\n",
    "  \n",
    "- **FEATURES**: Dimension table with temporal/environmental factors\n",
    "  - Granularity: Store + Week level (time-varying attributes)\n",
    "  - Contains: Economic indicators, weather, promotions, holidays\n",
    "\n",
    "#### **Duplicate column**\n",
    "- **IsHoliday**: Column does not appear to be needed for referencial integrety, one option can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped duplicate IsHoliday column from features dataset\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate IsHoliday column from features_df to avoid redundancy\n",
    "# Keep IsHoliday in sales_df as it's the primary fact table\n",
    "features_df_transform = features_df_transform.drop('IsHoliday', axis=1)\n",
    "\n",
    "print(\"Dropped duplicate IsHoliday column from features dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features table trimmed to end at 2012-10-26\n",
      "\n",
      "Orphaned stores in Sales (not in master): 0\n",
      "Orphaned stores in Master (not in sales): 0\n",
      "\n",
      "Orphaned sales combinations without features: 0\n",
      "Orphaned features combinations without sales: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for orphaned keys between datasets\n",
    "# Trim features table by last sales date\n",
    "last_sales_date = sales_df_transform['Date'].max()\n",
    "features_df_transform = features_df_transform[features_df_transform['Date'] <= last_sales_date]\n",
    "print(f\"Features table trimmed to end at {last_sales_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Store comparisons\n",
    "sales_stores = set(sales_df_transform['Store'].unique())\n",
    "master_stores = set(stores_df_transform['Store'].unique())\n",
    "orphaned_sales_stores = sales_stores - master_stores\n",
    "orphaned_master_stores = master_stores - sales_stores\n",
    "\n",
    "print(f\"\\nOrphaned stores in Sales (not in master): {len(orphaned_sales_stores)}\")\n",
    "print(f\"Orphaned stores in Master (not in sales): {len(orphaned_master_stores)}\")\n",
    "\n",
    "# Store-date combinations\n",
    "sales_keys = set(zip(sales_df_transform['Store'], sales_df_transform['Date']))\n",
    "features_keys = set(zip(features_df_transform['Store'], features_df_transform['Date']))\n",
    "orphaned_sales = sales_keys - features_keys\n",
    "orphaned_features = features_keys - sales_keys\n",
    "\n",
    "print(f\"\\nOrphaned sales combinations without features: {len(orphaned_sales):,}\")\n",
    "print(f\"Orphaned features combinations without sales: {len(orphaned_features):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the Tables\n",
    "\n",
    "It appears that there aren't any orphaned keys, I can use LEFT JOIN or INNER JOIN with the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denormalised dataset: 421,570 records, 16 columns\n",
      "Original sales records: 421,570 records, 5 columns\n",
      "\n",
      "Join validation:\n",
      "Missing store data after join: 0\n",
      "Missing feature data after join: 0\n",
      "\n",
      "Head of denormalised dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  Weekly_Sales  IsHoliday Type    Size  Temperature  \\\n",
       "0      1     1 2010-02-05      24924.50      False    A  151315        42.31   \n",
       "1      1     1 2010-02-12      46039.49       True    A  151315        38.51   \n",
       "2      1     1 2010-02-19      41595.55      False    A  151315        39.93   \n",
       "3      1     1 2010-02-26      19403.54      False    A  151315        46.63   \n",
       "4      1     1 2010-03-05      21827.90      False    A  151315        46.50   \n",
       "\n",
       "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "1       2.548        NaN        NaN        NaN        NaN        NaN   \n",
       "2       2.514        NaN        NaN        NaN        NaN        NaN   \n",
       "3       2.561        NaN        NaN        NaN        NaN        NaN   \n",
       "4       2.625        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "          CPI  Unemployment  \n",
       "0  211.096358         8.106  \n",
       "1  211.242170         8.106  \n",
       "2  211.289143         8.106  \n",
       "3  211.319643         8.106  \n",
       "4  211.350143         8.106  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left join merge of definitions and feature definitions to the sales fact table\n",
    "\n",
    "# Create complete dataset with all three tables joined\n",
    "denormalised_df_transform = sales_df_transform.merge(stores_df_transform, on='Store', how='left') \\\n",
    "                           .merge(features_df_transform, on=['Store', 'Date'], how='left')\n",
    "\n",
    "print(f\"Denormalised dataset: {denormalised_df_transform.shape[0]:,} records, {denormalised_df_transform.shape[1]} columns\")\n",
    "print(f\"Original sales records: {sales_df_transform.shape[0]:,} records, {sales_df_transform.shape[1]} columns\")\n",
    "\n",
    "# Verify join success - check for any null values in key columns\n",
    "null_stores = denormalised_df_transform['Type'].isnull().sum()\n",
    "null_features = denormalised_df_transform['Temperature'].isnull().sum()\n",
    "\n",
    "print(f\"\\nJoin validation:\")\n",
    "print(f\"Missing store data after join: {null_stores}\")\n",
    "print(f\"Missing feature data after join: {null_features}\")\n",
    "\n",
    "# Display sample of joined data\n",
    "print(f\"\\nHead of denormalised dataset:\")\n",
    "denormalised_df_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting Strategy\n",
    "\n",
    "Based on the date range data quality issues identified above, we'll create **two analysis datasets** to maximize data utility:\n",
    "\n",
    "#### **Dataset 1: General Analysis (Full Sales data Timeline)**\n",
    "- **Purpose:** Sales trends, seasonality, store performance analysis\n",
    "- **Timeline:** Complete sales data dataset (Feb 2010 - Oct 2012)\n",
    "- **Features:** Store, Date, Temperature, Fuel_Price, CPI, Unemployment, IsHoliday, Weekly_Sales\n",
    "- **Advantage:** Maximum data coverage for robust trend analysis\n",
    "\n",
    "#### **Dataset 2: Promotion and Markdown Analysis (Nov 2011 onwards)**\n",
    "- **Purpose:** Impact of markdowns and promotional strategies\n",
    "- **Timeline:** From Nov 2011 when MarkDown data becomes available - Oct 2012\n",
    "- **Features:** All features including MarkDown 1-5 columns\n",
    "- **Advantage:** Complete feature set for promotional impact analysis\n",
    "\n",
    "This approach allows me to:\n",
    "- **Maximise data usage** - Use full timeline where appropriate\n",
    "- **Maintain data quality** - Focus on complete records for markdown analysis\n",
    "- **Enable comprehensive insights** - Compare pre/post promotional periods\n",
    "\n",
    "---\n",
    "\n",
    "#### Implementing the Split\n",
    "\n",
    "**Naming Conventions:**\n",
    "- General analysis datasets: Keep existing names (`denormalised_df`)\n",
    "- Promotional analysis datasets: Use `promo_` prefix (`promo_denormalised_df`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promotional dataset created from denormalised table starting 2011-11-11:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Column</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Row Count</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing %</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>Sample Values</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Promo_Complete</td>\n",
       "      <td>MarkDown1</td>\n",
       "      <td>float64</td>\n",
       "      <td>151432</td>\n",
       "      <td>751</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2277</td>\n",
       "      <td>10382.9, 6074.12, 410.31</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Promo_Complete</td>\n",
       "      <td>MarkDown2</td>\n",
       "      <td>float64</td>\n",
       "      <td>151432</td>\n",
       "      <td>40184</td>\n",
       "      <td>26.54</td>\n",
       "      <td>1499</td>\n",
       "      <td>6115.67, 254.39, 98.0</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Promo_Complete</td>\n",
       "      <td>MarkDown3</td>\n",
       "      <td>float64</td>\n",
       "      <td>151432</td>\n",
       "      <td>14341</td>\n",
       "      <td>9.47</td>\n",
       "      <td>1662</td>\n",
       "      <td>215.07, 51.98, 55805.51</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Promo_Complete</td>\n",
       "      <td>MarkDown4</td>\n",
       "      <td>float64</td>\n",
       "      <td>151432</td>\n",
       "      <td>16465</td>\n",
       "      <td>10.87</td>\n",
       "      <td>1944</td>\n",
       "      <td>2406.62, 427.39, 8.0</td>\n",
       "      <td>Anonymized promotional markdown data (after No...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dataset     Column Data Type  Row Count  Missing Values  Missing %  \\\n",
       "9   Promo_Complete  MarkDown1   float64     151432             751       0.50   \n",
       "10  Promo_Complete  MarkDown2   float64     151432           40184      26.54   \n",
       "11  Promo_Complete  MarkDown3   float64     151432           14341       9.47   \n",
       "12  Promo_Complete  MarkDown4   float64     151432           16465      10.87   \n",
       "\n",
       "    Unique Values             Sample Values  \\\n",
       "9            2277  10382.9, 6074.12, 410.31   \n",
       "10           1499     6115.67, 254.39, 98.0   \n",
       "11           1662   215.07, 51.98, 55805.51   \n",
       "12           1944      2406.62, 427.39, 8.0   \n",
       "\n",
       "                                          Description  \n",
       "9   Anonymized promotional markdown data (after No...  \n",
       "10  Anonymized promotional markdown data (after No...  \n",
       "11  Anonymized promotional markdown data (after No...  \n",
       "12  Anonymized promotional markdown data (after No...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create promotional datasets (from first markdown date onwards) using the denormalised table\n",
    "promo_denormalised_df_transform = denormalised_df_transform[denormalised_df_transform['Date'] >= first_markdown_date].copy()\n",
    "\n",
    "# Create promotional datasets dictionary\n",
    "promo_datasets = {\n",
    "    'Promo_Complete': promo_denormalised_df_transform\n",
    "}\n",
    "\n",
    "# Generate data dictionary for promotional datasets\n",
    "promo_data_dictionary = create_data_dictionary(promo_datasets)\n",
    "\n",
    "print(f'Promotional dataset created from denormalised table starting {first_markdown_date.strftime(\"%Y-%m-%d\")}:')\n",
    "\n",
    "# Display promotional data dictionary filtered for rows with missing values\n",
    "promo_data_dictionary[promo_data_dictionary['Missing Values'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean after or before split???\n",
    "## Bais Analysis\n",
    "## Imputing / Null Management Required\n",
    "## Anomoly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transform datasets cleaned up. Ready for analysis.\n"
     ]
    }
   ],
   "source": [
    "# Create clean datasets from transformed data for analysis\n",
    "sales_df = denormalised_df_transform.copy()\n",
    "promo_sales_df = promo_denormalised_df_transform.copy()\n",
    "\n",
    "# Clean up temporary transform dataframes - no longer needed\n",
    "del sales_df_transform, features_df_transform, denormalised_df_transform, promo_denormalised_df_transform\n",
    "\n",
    "print(\"\\nTransform datasets cleaned up. Ready for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFQo3ycuO-v6"
   },
   "source": [
    "# Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 2 content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You may add as many sections as you want, as long as it supports your project workflow.\n",
    "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
